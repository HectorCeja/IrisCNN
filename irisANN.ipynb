{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## se carga dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c    d        class\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa\n",
       "5  5.4  3.9  1.7  0.4  Iris-setosa"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('iris.csv')\n",
    "dataset.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## se necesita convertir la última columna a valor número, para eso se utiliza LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelEncoder()\n",
    "lb.fit(dataset['class'])\n",
    "last_column_numeric = lb.transform(dataset['class'])\n",
    "last_column_numeric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## una vez convertido, se elimina la columa de string y se agrega la nueva columna de valores numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c    d  group\n",
       "0  5.1  3.5  1.4  0.2      0\n",
       "1  4.9  3.0  1.4  0.2      0\n",
       "2  4.7  3.2  1.3  0.2      0\n",
       "3  4.6  3.1  1.5  0.2      0\n",
       "4  5.0  3.6  1.4  0.2      0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop(columns='class', inplace=True)\n",
    "dataset['group'] = last_column_numeric\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convertimos a csv el nuevo data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('iris_numeric.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agregamos las ventanas para las series de tiempo y calculamos la media de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "dataset_soft = dataset.rolling(window=8, min_periods=1).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se define el tamaño de ventana que tendra la serie de tiempos, y se transforma a una colección de datos para el entrenamiento supervisado de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-5)</th>\n",
       "      <th>var2(t-5)</th>\n",
       "      <th>var3(t-5)</th>\n",
       "      <th>var4(t-5)</th>\n",
       "      <th>var5(t-5)</th>\n",
       "      <th>var1(t-4)</th>\n",
       "      <th>var2(t-4)</th>\n",
       "      <th>var3(t-4)</th>\n",
       "      <th>var4(t-4)</th>\n",
       "      <th>var5(t-4)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.1000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8600</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9500</td>\n",
       "      <td>3.383333</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9000</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9500</td>\n",
       "      <td>3.383333</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9000</td>\n",
       "      <td>3.385714</td>\n",
       "      <td>1.442857</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.9000</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.8250</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9000</td>\n",
       "      <td>3.385714</td>\n",
       "      <td>1.442857</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9125</td>\n",
       "      <td>3.387500</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.8250</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.8600</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9125</td>\n",
       "      <td>3.387500</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.8250</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.8600</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9500</td>\n",
       "      <td>3.383333</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8250</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.8250</td>\n",
       "      <td>3.325000</td>\n",
       "      <td>1.462500</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.9500</td>\n",
       "      <td>3.383333</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9000</td>\n",
       "      <td>3.385714</td>\n",
       "      <td>1.442857</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8250</td>\n",
       "      <td>3.325000</td>\n",
       "      <td>1.462500</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9125</td>\n",
       "      <td>3.387500</td>\n",
       "      <td>1.487500</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.9000</td>\n",
       "      <td>3.385714</td>\n",
       "      <td>1.442857</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9125</td>\n",
       "      <td>3.387500</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9125</td>\n",
       "      <td>3.387500</td>\n",
       "      <td>1.487500</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9375</td>\n",
       "      <td>3.425000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.9125</td>\n",
       "      <td>3.387500</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.8250</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9375</td>\n",
       "      <td>3.425000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9125</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.8250</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.8250</td>\n",
       "      <td>3.325000</td>\n",
       "      <td>1.462500</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9125</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7750</td>\n",
       "      <td>3.237500</td>\n",
       "      <td>1.425000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.8250</td>\n",
       "      <td>3.325000</td>\n",
       "      <td>1.462500</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9125</td>\n",
       "      <td>3.387500</td>\n",
       "      <td>1.487500</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.7750</td>\n",
       "      <td>3.237500</td>\n",
       "      <td>1.425000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9250</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1(t-5)  var2(t-5)  var3(t-5)  var4(t-5)  var5(t-5)  var1(t-4)  \\\n",
       "5      5.1000   3.500000   1.400000   0.200000        0.0     5.0000   \n",
       "6      5.0000   3.250000   1.400000   0.200000        0.0     4.9000   \n",
       "7      4.9000   3.233333   1.366667   0.200000        0.0     4.8250   \n",
       "8      4.8250   3.200000   1.400000   0.200000        0.0     4.8600   \n",
       "9      4.8600   3.280000   1.400000   0.200000        0.0     4.9500   \n",
       "10     4.9500   3.383333   1.450000   0.233333        0.0     4.9000   \n",
       "11     4.9000   3.385714   1.442857   0.242857        0.0     4.9125   \n",
       "12     4.9125   3.387500   1.450000   0.237500        0.0     4.8250   \n",
       "13     4.8250   3.312500   1.450000   0.237500        0.0     4.8250   \n",
       "14     4.8250   3.325000   1.462500   0.225000        0.0     4.9125   \n",
       "\n",
       "    var2(t-4)  var3(t-4)  var4(t-4)  var5(t-4)   ...     var1(t-1)  var2(t-1)  \\\n",
       "5    3.250000   1.400000   0.200000        0.0   ...        4.8600   3.280000   \n",
       "6    3.233333   1.366667   0.200000        0.0   ...        4.9500   3.383333   \n",
       "7    3.200000   1.400000   0.200000        0.0   ...        4.9000   3.385714   \n",
       "8    3.280000   1.400000   0.200000        0.0   ...        4.9125   3.387500   \n",
       "9    3.383333   1.450000   0.233333        0.0   ...        4.8250   3.312500   \n",
       "10   3.385714   1.442857   0.242857        0.0   ...        4.8250   3.325000   \n",
       "11   3.387500   1.450000   0.237500        0.0   ...        4.9125   3.387500   \n",
       "12   3.312500   1.450000   0.237500        0.0   ...        4.9375   3.425000   \n",
       "13   3.325000   1.462500   0.225000        0.0   ...        4.9125   3.350000   \n",
       "14   3.387500   1.487500   0.225000        0.0   ...        4.7750   3.237500   \n",
       "\n",
       "    var3(t-1)  var4(t-1)  var5(t-1)  var1(t)   var2(t)   var3(t)   var4(t)  \\\n",
       "5    1.400000   0.200000        0.0   4.9500  3.383333  1.450000  0.233333   \n",
       "6    1.450000   0.233333        0.0   4.9000  3.385714  1.442857  0.242857   \n",
       "7    1.442857   0.242857        0.0   4.9125  3.387500  1.450000  0.237500   \n",
       "8    1.450000   0.237500        0.0   4.8250  3.312500  1.450000  0.237500   \n",
       "9    1.450000   0.237500        0.0   4.8250  3.325000  1.462500  0.225000   \n",
       "10   1.462500   0.225000        0.0   4.9125  3.387500  1.487500  0.225000   \n",
       "11   1.487500   0.225000        0.0   4.9375  3.425000  1.500000  0.225000   \n",
       "12   1.500000   0.225000        0.0   4.9125  3.350000  1.500000  0.212500   \n",
       "13   1.500000   0.212500        0.0   4.7750  3.237500  1.425000  0.175000   \n",
       "14   1.425000   0.175000        0.0   4.9250  3.312500  1.400000  0.162500   \n",
       "\n",
       "    var5(t)  \n",
       "5       0.0  \n",
       "6       0.0  \n",
       "7       0.0  \n",
       "8       0.0  \n",
       "9       0.0  \n",
       "10      0.0  \n",
       "11      0.0  \n",
       "12      0.0  \n",
       "13      0.0  \n",
       "14      0.0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Tools as tls\n",
    "\n",
    "size = 5\n",
    "\n",
    "dataset_serialized = tls.series_to_supervised(dataset_soft,size, n_out=1, dropnan = True)\n",
    "dataset_serialized.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## se normalizan datos entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3    4         5         6   \\\n",
      "0    0.151163  0.736842  0.013889  0.018987  0.0  0.104651  0.526316   \n",
      "1    0.104651  0.526316  0.013889  0.018987  0.0  0.058140  0.512281   \n",
      "2    0.058140  0.512281  0.006481  0.018987  0.0  0.023256  0.484211   \n",
      "3    0.023256  0.484211  0.013889  0.018987  0.0  0.039535  0.551579   \n",
      "4    0.039535  0.551579  0.013889  0.018987  0.0  0.081395  0.638596   \n",
      "5    0.081395  0.638596  0.025000  0.035865  0.0  0.058140  0.640602   \n",
      "6    0.058140  0.640602  0.023413  0.040687  0.0  0.063953  0.642105   \n",
      "7    0.063953  0.642105  0.025000  0.037975  0.0  0.023256  0.578947   \n",
      "8    0.023256  0.578947  0.025000  0.037975  0.0  0.023256  0.589474   \n",
      "9    0.023256  0.589474  0.027778  0.031646  0.0  0.063953  0.642105   \n",
      "10   0.063953  0.642105  0.033333  0.031646  0.0  0.075581  0.673684   \n",
      "11   0.075581  0.673684  0.036111  0.031646  0.0  0.063953  0.610526   \n",
      "12   0.063953  0.610526  0.036111  0.025316  0.0  0.000000  0.515789   \n",
      "13   0.000000  0.515789  0.019444  0.006329  0.0  0.069767  0.578947   \n",
      "14   0.069767  0.578947  0.013889  0.000000  0.0  0.110465  0.684211   \n",
      "15   0.110465  0.684211  0.013889  0.012658  0.0  0.168605  0.789474   \n",
      "16   0.168605  0.789474  0.011111  0.025316  0.0  0.180233  0.831579   \n",
      "17   0.180233  0.831579  0.008333  0.037975  0.0  0.197674  0.842105   \n",
      "18   0.197674  0.842105  0.013889  0.044304  0.0  0.215116  0.884211   \n",
      "19   0.215116  0.884211  0.011111  0.050633  0.0  0.250000  0.926316   \n",
      "20   0.250000  0.926316  0.019444  0.056962  0.0  0.296512  1.000000   \n",
      "21   0.296512  1.000000  0.030556  0.075949  0.0  0.226744  0.957895   \n",
      "22   0.226744  0.957895  0.025000  0.075949  0.0  0.191860  0.842105   \n",
      "23   0.191860  0.842105  0.030556  0.082278  0.0  0.156977  0.789474   \n",
      "24   0.156977  0.789474  0.047222  0.069620  0.0  0.151163  0.736842   \n",
      "25   0.151163  0.736842  0.052778  0.063291  0.0  0.110465  0.694737   \n",
      "26   0.110465  0.694737  0.050000  0.069620  0.0  0.116279  0.663158   \n",
      "27   0.116279  0.663158  0.050000  0.063291  0.0  0.104651  0.663158   \n",
      "28   0.104651  0.663158  0.041667  0.063291  0.0  0.081395  0.610526   \n",
      "29   0.081395  0.610526  0.044444  0.050633  0.0  0.093023  0.557895   \n",
      "..        ...       ...       ...       ...  ...       ...       ...   \n",
      "115  0.773256  0.263158  0.902778  0.993671  1.0  0.761628  0.315789   \n",
      "116  0.761628  0.315789  0.894444  0.993671  1.0  0.790698  0.336842   \n",
      "117  0.790698  0.336842  0.911111  0.974684  1.0  0.860465  0.273684   \n",
      "118  0.860465  0.273684  0.961111  0.993671  1.0  0.837209  0.221053   \n",
      "119  0.837209  0.221053  0.952778  0.968354  1.0  0.843023  0.242105   \n",
      "120  0.843023  0.242105  0.958333  0.981013  1.0  0.837209  0.273684   \n",
      "121  0.837209  0.273684  0.955556  0.981013  1.0  0.947674  0.273684   \n",
      "122  0.947674  0.273684  1.000000  0.955696  1.0  0.941860  0.221053   \n",
      "123  0.941860  0.221053  0.988889  0.924051  1.0  0.953488  0.252632   \n",
      "124  0.953488  0.252632  0.994444  0.943038  1.0  0.924419  0.189474   \n",
      "125  0.924419  0.189474  0.975000  0.917722  1.0  0.837209  0.210526   \n",
      "126  0.837209  0.210526  0.916667  0.886076  1.0  0.843023  0.294737   \n",
      "127  0.843023  0.294737  0.913889  0.905063  1.0  0.813953  0.252632   \n",
      "128  0.813953  0.252632  0.911111  0.892405  1.0  0.906977  0.273684   \n",
      "129  0.906977  0.273684  0.936111  0.867089  1.0  0.889535  0.273684   \n",
      "130  0.889535  0.273684  0.919444  0.860759  1.0  0.982558  0.389474   \n",
      "131  0.982558  0.389474  0.961111  0.873418  1.0  0.965116  0.336842   \n",
      "132  0.965116  0.336842  0.958333  0.879747  1.0  0.912791  0.294737   \n",
      "133  0.912791  0.294737  0.933333  0.860759  1.0  0.906977  0.273684   \n",
      "134  0.906977  0.273684  0.955556  0.835443  1.0  1.000000  0.273684   \n",
      "135  1.000000  0.273684  0.988889  0.867089  1.0  0.994186  0.336842   \n",
      "136  0.994186  0.336842  0.988889  0.886076  1.0  0.947674  0.347368   \n",
      "137  0.947674  0.347368  0.980556  0.898734  1.0  0.866279  0.368421   \n",
      "138  0.866279  0.368421  0.944444  0.892405  1.0  0.808140  0.294737   \n",
      "139  0.808140  0.294737  0.916667  0.898734  1.0  0.825581  0.326316   \n",
      "140  0.825581  0.326316  0.916667  0.911392  1.0  0.860465  0.357895   \n",
      "141  0.860465  0.357895  0.916667  0.962025  1.0  0.843023  0.368421   \n",
      "142  0.843023  0.368421  0.902778  0.993671  1.0  0.790698  0.389474   \n",
      "143  0.790698  0.389474  0.897222  0.993671  1.0  0.813953  0.378947   \n",
      "144  0.813953  0.378947  0.900000  1.000000  1.0  0.831395  0.368421   \n",
      "\n",
      "           7         8    9  ...         20        21        22        23  \\\n",
      "0    0.013889  0.018405  0.0 ...   0.039535  0.551579  0.013889  0.018293   \n",
      "1    0.006481  0.018405  0.0 ...   0.081395  0.638596  0.025000  0.034553   \n",
      "2    0.013889  0.018405  0.0 ...   0.058140  0.640602  0.023413  0.039199   \n",
      "3    0.013889  0.018405  0.0 ...   0.063953  0.642105  0.025000  0.036585   \n",
      "4    0.025000  0.034765  0.0 ...   0.023256  0.578947  0.025000  0.036585   \n",
      "5    0.023413  0.039439  0.0 ...   0.023256  0.589474  0.027778  0.030488   \n",
      "6    0.025000  0.036810  0.0 ...   0.063953  0.642105  0.033333  0.030488   \n",
      "7    0.025000  0.036810  0.0 ...   0.075581  0.673684  0.036111  0.030488   \n",
      "8    0.027778  0.030675  0.0 ...   0.063953  0.610526  0.036111  0.024390   \n",
      "9    0.033333  0.030675  0.0 ...   0.000000  0.515789  0.019444  0.006098   \n",
      "10   0.036111  0.030675  0.0 ...   0.069767  0.578947  0.013889  0.000000   \n",
      "11   0.036111  0.024540  0.0 ...   0.110465  0.684211  0.013889  0.012195   \n",
      "12   0.019444  0.006135  0.0 ...   0.168605  0.789474  0.011111  0.024390   \n",
      "13   0.013889  0.000000  0.0 ...   0.180233  0.831579  0.008333  0.036585   \n",
      "14   0.013889  0.012270  0.0 ...   0.197674  0.842105  0.013889  0.042683   \n",
      "15   0.011111  0.024540  0.0 ...   0.215116  0.884211  0.011111  0.048780   \n",
      "16   0.008333  0.036810  0.0 ...   0.250000  0.926316  0.019444  0.054878   \n",
      "17   0.013889  0.042945  0.0 ...   0.296512  1.000000  0.030556  0.073171   \n",
      "18   0.011111  0.049080  0.0 ...   0.226744  0.957895  0.025000  0.073171   \n",
      "19   0.019444  0.055215  0.0 ...   0.191860  0.842105  0.030556  0.079268   \n",
      "20   0.030556  0.073620  0.0 ...   0.156977  0.789474  0.047222  0.067073   \n",
      "21   0.025000  0.073620  0.0 ...   0.151163  0.736842  0.052778  0.060976   \n",
      "22   0.030556  0.079755  0.0 ...   0.110465  0.694737  0.050000  0.067073   \n",
      "23   0.047222  0.067485  0.0 ...   0.116279  0.663158  0.050000  0.060976   \n",
      "24   0.052778  0.061350  0.0 ...   0.104651  0.663158  0.041667  0.060976   \n",
      "25   0.050000  0.067485  0.0 ...   0.081395  0.610526  0.044444  0.048780   \n",
      "26   0.050000  0.061350  0.0 ...   0.093023  0.557895  0.061111  0.048780   \n",
      "27   0.041667  0.061350  0.0 ...   0.110465  0.568421  0.055556  0.042683   \n",
      "28   0.044444  0.049080  0.0 ...   0.133721  0.642105  0.044444  0.036585   \n",
      "29   0.061111  0.049080  0.0 ...   0.162791  0.768421  0.038889  0.036585   \n",
      "..        ...       ...  ... ...        ...       ...       ...       ...   \n",
      "115  0.894444  0.963190  1.0 ...   0.837209  0.221053  0.952778  0.932927   \n",
      "116  0.911111  0.944785  1.0 ...   0.843023  0.242105  0.958333  0.945122   \n",
      "117  0.961111  0.963190  1.0 ...   0.837209  0.273684  0.955556  0.945122   \n",
      "118  0.952778  0.938650  1.0 ...   0.947674  0.273684  1.000000  0.920732   \n",
      "119  0.958333  0.950920  1.0 ...   0.941860  0.221053  0.988889  0.890244   \n",
      "120  0.955556  0.950920  1.0 ...   0.953488  0.252632  0.994444  0.908537   \n",
      "121  1.000000  0.926380  1.0 ...   0.924419  0.189474  0.975000  0.884146   \n",
      "122  0.988889  0.895706  1.0 ...   0.837209  0.210526  0.916667  0.853659   \n",
      "123  0.994444  0.914110  1.0 ...   0.843023  0.294737  0.913889  0.871951   \n",
      "124  0.975000  0.889571  1.0 ...   0.813953  0.252632  0.911111  0.859756   \n",
      "125  0.916667  0.858896  1.0 ...   0.906977  0.273684  0.936111  0.835366   \n",
      "126  0.913889  0.877301  1.0 ...   0.889535  0.273684  0.919444  0.829268   \n",
      "127  0.911111  0.865031  1.0 ...   0.982558  0.389474  0.961111  0.841463   \n",
      "128  0.936111  0.840491  1.0 ...   0.965116  0.336842  0.958333  0.847561   \n",
      "129  0.919444  0.834356  1.0 ...   0.912791  0.294737  0.933333  0.829268   \n",
      "130  0.961111  0.846626  1.0 ...   0.906977  0.273684  0.955556  0.804878   \n",
      "131  0.958333  0.852761  1.0 ...   1.000000  0.273684  0.988889  0.835366   \n",
      "132  0.933333  0.834356  1.0 ...   0.994186  0.336842  0.988889  0.853659   \n",
      "133  0.955556  0.809816  1.0 ...   0.947674  0.347368  0.980556  0.865854   \n",
      "134  0.988889  0.840491  1.0 ...   0.866279  0.368421  0.944444  0.859756   \n",
      "135  0.988889  0.858896  1.0 ...   0.808140  0.294737  0.916667  0.865854   \n",
      "136  0.980556  0.871166  1.0 ...   0.825581  0.326316  0.916667  0.878049   \n",
      "137  0.944444  0.865031  1.0 ...   0.860465  0.357895  0.916667  0.926829   \n",
      "138  0.916667  0.871166  1.0 ...   0.843023  0.368421  0.902778  0.957317   \n",
      "139  0.916667  0.883436  1.0 ...   0.790698  0.389474  0.897222  0.957317   \n",
      "140  0.916667  0.932515  1.0 ...   0.813953  0.378947  0.900000  0.963415   \n",
      "141  0.902778  0.963190  1.0 ...   0.831395  0.368421  0.891667  0.993902   \n",
      "142  0.897222  0.963190  1.0 ...   0.848837  0.315789  0.897222  1.000000   \n",
      "143  0.900000  0.969325  1.0 ...   0.825581  0.305263  0.891667  0.993902   \n",
      "144  0.891667  1.000000  1.0 ...   0.796512  0.336842  0.886111  0.987805   \n",
      "\n",
      "      24        25        26        27        28   29  \n",
      "0    0.0  0.081395  0.638596  0.025000  0.034553  0.0  \n",
      "1    0.0  0.058140  0.640602  0.023413  0.039199  0.0  \n",
      "2    0.0  0.063953  0.642105  0.025000  0.036585  0.0  \n",
      "3    0.0  0.023256  0.578947  0.025000  0.036585  0.0  \n",
      "4    0.0  0.023256  0.589474  0.027778  0.030488  0.0  \n",
      "5    0.0  0.063953  0.642105  0.033333  0.030488  0.0  \n",
      "6    0.0  0.075581  0.673684  0.036111  0.030488  0.0  \n",
      "7    0.0  0.063953  0.610526  0.036111  0.024390  0.0  \n",
      "8    0.0  0.000000  0.515789  0.019444  0.006098  0.0  \n",
      "9    0.0  0.069767  0.578947  0.013889  0.000000  0.0  \n",
      "10   0.0  0.110465  0.684211  0.013889  0.012195  0.0  \n",
      "11   0.0  0.168605  0.789474  0.011111  0.024390  0.0  \n",
      "12   0.0  0.180233  0.831579  0.008333  0.036585  0.0  \n",
      "13   0.0  0.197674  0.842105  0.013889  0.042683  0.0  \n",
      "14   0.0  0.215116  0.884211  0.011111  0.048780  0.0  \n",
      "15   0.0  0.250000  0.926316  0.019444  0.054878  0.0  \n",
      "16   0.0  0.296512  1.000000  0.030556  0.073171  0.0  \n",
      "17   0.0  0.226744  0.957895  0.025000  0.073171  0.0  \n",
      "18   0.0  0.191860  0.842105  0.030556  0.079268  0.0  \n",
      "19   0.0  0.156977  0.789474  0.047222  0.067073  0.0  \n",
      "20   0.0  0.151163  0.736842  0.052778  0.060976  0.0  \n",
      "21   0.0  0.110465  0.694737  0.050000  0.067073  0.0  \n",
      "22   0.0  0.116279  0.663158  0.050000  0.060976  0.0  \n",
      "23   0.0  0.104651  0.663158  0.041667  0.060976  0.0  \n",
      "24   0.0  0.081395  0.610526  0.044444  0.048780  0.0  \n",
      "25   0.0  0.093023  0.557895  0.061111  0.048780  0.0  \n",
      "26   0.0  0.110465  0.568421  0.055556  0.042683  0.0  \n",
      "27   0.0  0.133721  0.642105  0.044444  0.036585  0.0  \n",
      "28   0.0  0.162791  0.768421  0.038889  0.036585  0.0  \n",
      "29   0.0  0.156977  0.736842  0.036111  0.018293  0.0  \n",
      "..   ...       ...       ...       ...       ...  ...  \n",
      "115  1.0  0.843023  0.242105  0.958333  0.945122  1.0  \n",
      "116  1.0  0.837209  0.273684  0.955556  0.945122  1.0  \n",
      "117  1.0  0.947674  0.273684  1.000000  0.920732  1.0  \n",
      "118  1.0  0.941860  0.221053  0.988889  0.890244  1.0  \n",
      "119  1.0  0.953488  0.252632  0.994444  0.908537  1.0  \n",
      "120  1.0  0.924419  0.189474  0.975000  0.884146  1.0  \n",
      "121  1.0  0.837209  0.210526  0.916667  0.853659  1.0  \n",
      "122  1.0  0.843023  0.294737  0.913889  0.871951  1.0  \n",
      "123  1.0  0.813953  0.252632  0.911111  0.859756  1.0  \n",
      "124  1.0  0.906977  0.273684  0.936111  0.835366  1.0  \n",
      "125  1.0  0.889535  0.273684  0.919444  0.829268  1.0  \n",
      "126  1.0  0.982558  0.389474  0.961111  0.841463  1.0  \n",
      "127  1.0  0.965116  0.336842  0.958333  0.847561  1.0  \n",
      "128  1.0  0.912791  0.294737  0.933333  0.829268  1.0  \n",
      "129  1.0  0.906977  0.273684  0.955556  0.804878  1.0  \n",
      "130  1.0  1.000000  0.273684  0.988889  0.835366  1.0  \n",
      "131  1.0  0.994186  0.336842  0.988889  0.853659  1.0  \n",
      "132  1.0  0.947674  0.347368  0.980556  0.865854  1.0  \n",
      "133  1.0  0.866279  0.368421  0.944444  0.859756  1.0  \n",
      "134  1.0  0.808140  0.294737  0.916667  0.865854  1.0  \n",
      "135  1.0  0.825581  0.326316  0.916667  0.878049  1.0  \n",
      "136  1.0  0.860465  0.357895  0.916667  0.926829  1.0  \n",
      "137  1.0  0.843023  0.368421  0.902778  0.957317  1.0  \n",
      "138  1.0  0.790698  0.389474  0.897222  0.957317  1.0  \n",
      "139  1.0  0.813953  0.378947  0.900000  0.963415  1.0  \n",
      "140  1.0  0.831395  0.368421  0.891667  0.993902  1.0  \n",
      "141  1.0  0.848837  0.315789  0.897222  1.000000  1.0  \n",
      "142  1.0  0.825581  0.305263  0.891667  0.993902  1.0  \n",
      "143  1.0  0.796512  0.336842  0.886111  0.987805  1.0  \n",
      "144  1.0  0.738372  0.326316  0.886111  0.957317  1.0  \n",
      "\n",
      "[145 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "datasetnorm = preprocessing.minmax_scale(dataset_serialized, feature_range=(0, 1))\n",
    "datasetnorm = DataFrame(datasetnorm)\n",
    "print(datasetnorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "zy = datasetnorm.iloc[:, -1:]\n",
    "zx = datasetnorm.iloc[:, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 29) (116, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(zx, dtype='float64')\n",
    "y = np.array(zy, dtype='float64')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=20)\n",
    "\n",
    "X_test_noshape = X_test\n",
    "\n",
    "print(X_train.shape, y_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 1, 29) (116, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "y_train = y_train.reshape((y_train.shape[0], 1, y_train.shape[1]))\n",
    "y_test = y_test.reshape((y_test.shape[0], 1, y_test.shape[1]))\n",
    "\n",
    "print(X_train.shape, y_train.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential() \n",
    "model.add(Dense(8, activation = 'relu', input_shape=(X_train.shape[1], X_train.shape[2]))) # importante declarar correctamente shape\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## etrenamos el algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/50\n",
      "116/116 [==============================] - 0s 3ms/step - loss: 0.2526 - acc: 0.3103 - val_loss: 0.1781 - val_acc: 0.3103\n",
      "Epoch 2/50\n",
      "116/116 [==============================] - 0s 65us/step - loss: 0.1557 - acc: 0.3448 - val_loss: 0.1034 - val_acc: 0.4483\n",
      "Epoch 3/50\n",
      "116/116 [==============================] - 0s 83us/step - loss: 0.0861 - acc: 0.5776 - val_loss: 0.0551 - val_acc: 0.5517\n",
      "Epoch 4/50\n",
      "116/116 [==============================] - 0s 125us/step - loss: 0.0446 - acc: 0.6207 - val_loss: 0.0302 - val_acc: 0.5517\n",
      "Epoch 5/50\n",
      "116/116 [==============================] - 0s 88us/step - loss: 0.0254 - acc: 0.6207 - val_loss: 0.0210 - val_acc: 0.5517\n",
      "Epoch 6/50\n",
      "116/116 [==============================] - 0s 103us/step - loss: 0.0198 - acc: 0.6207 - val_loss: 0.0187 - val_acc: 0.5517\n",
      "Epoch 7/50\n",
      "116/116 [==============================] - 0s 105us/step - loss: 0.0183 - acc: 0.6207 - val_loss: 0.0169 - val_acc: 0.5517\n",
      "Epoch 8/50\n",
      "116/116 [==============================] - 0s 122us/step - loss: 0.0161 - acc: 0.6207 - val_loss: 0.0139 - val_acc: 0.5517\n",
      "Epoch 9/50\n",
      "116/116 [==============================] - 0s 117us/step - loss: 0.0130 - acc: 0.6207 - val_loss: 0.0107 - val_acc: 0.5517\n",
      "Epoch 10/50\n",
      "116/116 [==============================] - 0s 93us/step - loss: 0.0101 - acc: 0.6207 - val_loss: 0.0084 - val_acc: 0.5517\n",
      "Epoch 11/50\n",
      "116/116 [==============================] - 0s 61us/step - loss: 0.0081 - acc: 0.6207 - val_loss: 0.0070 - val_acc: 0.5517\n",
      "Epoch 12/50\n",
      "116/116 [==============================] - 0s 85us/step - loss: 0.0069 - acc: 0.6207 - val_loss: 0.0061 - val_acc: 0.5517\n",
      "Epoch 13/50\n",
      "116/116 [==============================] - 0s 83us/step - loss: 0.0061 - acc: 0.6207 - val_loss: 0.0053 - val_acc: 0.5517\n",
      "Epoch 14/50\n",
      "116/116 [==============================] - 0s 73us/step - loss: 0.0053 - acc: 0.6207 - val_loss: 0.0046 - val_acc: 0.5517\n",
      "Epoch 15/50\n",
      "116/116 [==============================] - 0s 95us/step - loss: 0.0046 - acc: 0.6207 - val_loss: 0.0040 - val_acc: 0.5517\n",
      "Epoch 16/50\n",
      "116/116 [==============================] - 0s 69us/step - loss: 0.0040 - acc: 0.6207 - val_loss: 0.0035 - val_acc: 0.5517\n",
      "Epoch 17/50\n",
      "116/116 [==============================] - 0s 69us/step - loss: 0.0036 - acc: 0.6207 - val_loss: 0.0032 - val_acc: 0.5517\n",
      "Epoch 18/50\n",
      "116/116 [==============================] - 0s 118us/step - loss: 0.0033 - acc: 0.6207 - val_loss: 0.0029 - val_acc: 0.5517\n",
      "Epoch 19/50\n",
      "116/116 [==============================] - 0s 119us/step - loss: 0.0030 - acc: 0.6207 - val_loss: 0.0026 - val_acc: 0.5517\n",
      "Epoch 20/50\n",
      "116/116 [==============================] - 0s 93us/step - loss: 0.0027 - acc: 0.6207 - val_loss: 0.0024 - val_acc: 0.5517\n",
      "Epoch 21/50\n",
      "116/116 [==============================] - 0s 124us/step - loss: 0.0025 - acc: 0.6207 - val_loss: 0.0022 - val_acc: 0.5517\n",
      "Epoch 22/50\n",
      "116/116 [==============================] - 0s 105us/step - loss: 0.0024 - acc: 0.6207 - val_loss: 0.0021 - val_acc: 0.5517\n",
      "Epoch 23/50\n",
      "116/116 [==============================] - 0s 99us/step - loss: 0.0022 - acc: 0.6207 - val_loss: 0.0019 - val_acc: 0.5517\n",
      "Epoch 24/50\n",
      "116/116 [==============================] - 0s 93us/step - loss: 0.0021 - acc: 0.6207 - val_loss: 0.0018 - val_acc: 0.5517\n",
      "Epoch 25/50\n",
      "116/116 [==============================] - 0s 68us/step - loss: 0.0020 - acc: 0.6207 - val_loss: 0.0018 - val_acc: 0.5517\n",
      "Epoch 26/50\n",
      "116/116 [==============================] - 0s 76us/step - loss: 0.0020 - acc: 0.6207 - val_loss: 0.0017 - val_acc: 0.5517\n",
      "Epoch 27/50\n",
      "116/116 [==============================] - 0s 72us/step - loss: 0.0019 - acc: 0.6207 - val_loss: 0.0016 - val_acc: 0.5517\n",
      "Epoch 28/50\n",
      "116/116 [==============================] - 0s 116us/step - loss: 0.0018 - acc: 0.6207 - val_loss: 0.0016 - val_acc: 0.5517\n",
      "Epoch 29/50\n",
      "116/116 [==============================] - 0s 93us/step - loss: 0.0018 - acc: 0.6207 - val_loss: 0.0015 - val_acc: 0.5517\n",
      "Epoch 30/50\n",
      "116/116 [==============================] - 0s 87us/step - loss: 0.0018 - acc: 0.6207 - val_loss: 0.0015 - val_acc: 0.5517\n",
      "Epoch 31/50\n",
      "116/116 [==============================] - 0s 92us/step - loss: 0.0017 - acc: 0.6207 - val_loss: 0.0015 - val_acc: 0.5517\n",
      "Epoch 32/50\n",
      "116/116 [==============================] - 0s 84us/step - loss: 0.0017 - acc: 0.6207 - val_loss: 0.0014 - val_acc: 0.5517\n",
      "Epoch 33/50\n",
      "116/116 [==============================] - 0s 72us/step - loss: 0.0017 - acc: 0.6207 - val_loss: 0.0014 - val_acc: 0.5517\n",
      "Epoch 34/50\n",
      "116/116 [==============================] - 0s 122us/step - loss: 0.0017 - acc: 0.6207 - val_loss: 0.0014 - val_acc: 0.5517\n",
      "Epoch 35/50\n",
      "116/116 [==============================] - 0s 105us/step - loss: 0.0016 - acc: 0.6207 - val_loss: 0.0014 - val_acc: 0.5517\n",
      "Epoch 36/50\n",
      "116/116 [==============================] - 0s 97us/step - loss: 0.0016 - acc: 0.6207 - val_loss: 0.0014 - val_acc: 0.5517\n",
      "Epoch 37/50\n",
      "116/116 [==============================] - 0s 111us/step - loss: 0.0016 - acc: 0.6207 - val_loss: 0.0014 - val_acc: 0.5517\n",
      "Epoch 38/50\n",
      "116/116 [==============================] - 0s 131us/step - loss: 0.0016 - acc: 0.6207 - val_loss: 0.0014 - val_acc: 0.5517\n",
      "Epoch 39/50\n",
      "116/116 [==============================] - 0s 107us/step - loss: 0.0016 - acc: 0.6207 - val_loss: 0.0014 - val_acc: 0.5517\n",
      "Epoch 40/50\n",
      "116/116 [==============================] - 0s 111us/step - loss: 0.0016 - acc: 0.6207 - val_loss: 0.0013 - val_acc: 0.5517\n",
      "Epoch 41/50\n",
      "116/116 [==============================] - 0s 155us/step - loss: 0.0016 - acc: 0.6207 - val_loss: 0.0013 - val_acc: 0.5517\n",
      "Epoch 42/50\n",
      "116/116 [==============================] - 0s 93us/step - loss: 0.0016 - acc: 0.6207 - val_loss: 0.0013 - val_acc: 0.5517\n",
      "Epoch 43/50\n",
      "116/116 [==============================] - 0s 110us/step - loss: 0.0016 - acc: 0.6207 - val_loss: 0.0013 - val_acc: 0.5517\n",
      "Epoch 44/50\n",
      "116/116 [==============================] - 0s 123us/step - loss: 0.0016 - acc: 0.6207 - val_loss: 0.0013 - val_acc: 0.5517\n",
      "Epoch 45/50\n",
      "116/116 [==============================] - 0s 121us/step - loss: 0.0016 - acc: 0.6207 - val_loss: 0.0013 - val_acc: 0.5517\n",
      "Epoch 46/50\n",
      "116/116 [==============================] - 0s 131us/step - loss: 0.0016 - acc: 0.6207 - val_loss: 0.0013 - val_acc: 0.5517\n",
      "Epoch 47/50\n",
      "116/116 [==============================] - 0s 157us/step - loss: 0.0015 - acc: 0.6207 - val_loss: 0.0013 - val_acc: 0.5517\n",
      "Epoch 48/50\n",
      "116/116 [==============================] - 0s 101us/step - loss: 0.0015 - acc: 0.6207 - val_loss: 0.0013 - val_acc: 0.5517\n",
      "Epoch 49/50\n",
      "116/116 [==============================] - 0s 161us/step - loss: 0.0015 - acc: 0.6207 - val_loss: 0.0013 - val_acc: 0.5517\n",
      "Epoch 50/50\n",
      "116/116 [==============================] - 0s 109us/step - loss: 0.0015 - acc: 0.6207 - val_loss: 0.0013 - val_acc: 0.5517\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, batch_size=24, validation_data=(X_test, y_test), verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## graficamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mean_squared_error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-c1d4614d28d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ggplot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_mean_squared_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean_squared_error'"
     ]
    }
   ],
   "source": [
    "pyplot.style.use(\"ggplot\")\n",
    "pyplot.plot(history.history['mean_squared_error'], label='mse')\n",
    "pyplot.plot(history.history['val_mean_squared_error'], label='val_mse')\n",
    "pyplot.xlabel('Epochs')\n",
    "pyplot.ylabel('Value')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## realizamos prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.4440159e-01],\n",
       "       [ 1.0251695e-02],\n",
       "       [-2.4532650e-02],\n",
       "       [ 9.1873777e-01],\n",
       "       [ 3.6606452e-01],\n",
       "       [ 4.0880740e-03],\n",
       "       [ 4.8881516e-01],\n",
       "       [ 6.2595904e-03],\n",
       "       [ 9.9226725e-01],\n",
       "       [ 4.7301400e-01],\n",
       "       [-1.4331161e-02],\n",
       "       [ 9.7183073e-01],\n",
       "       [ 9.4522697e-01],\n",
       "       [ 5.6370628e-01],\n",
       "       [-1.9202568e-04],\n",
       "       [ 6.8291712e-01],\n",
       "       [ 4.3016204e-01],\n",
       "       [ 1.0346897e+00],\n",
       "       [-1.9740542e-02],\n",
       "       [ 4.9168971e-01],\n",
       "       [ 5.1458991e-01],\n",
       "       [ 5.6944805e-01],\n",
       "       [ 5.8040422e-01],\n",
       "       [ 5.2571440e-01],\n",
       "       [-7.2221006e-03],\n",
       "       [ 5.1655030e-01],\n",
       "       [ 8.2408916e-03],\n",
       "       [ 1.0120716e+00],\n",
       "       [ 9.8513156e-01]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test, 10, verbose=2)\n",
    "predicted = predictions.transpose(2,0,1).reshape(-1,predictions.shape[1])\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## precisión de 55%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "29/29 [==============================] - 0s 151us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0012940416345372796, 0.5517241358757019]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5   ],\n",
       "       [0.    ],\n",
       "       [0.    ],\n",
       "       [1.    ],\n",
       "       [0.375 ],\n",
       "       [0.    ],\n",
       "       [0.5   ],\n",
       "       [0.    ],\n",
       "       [1.    ],\n",
       "       [0.5   ],\n",
       "       [0.    ],\n",
       "       [1.    ],\n",
       "       [1.    ],\n",
       "       [0.5   ],\n",
       "       [0.    ],\n",
       "       [0.75  ],\n",
       "       [0.4375],\n",
       "       [1.    ],\n",
       "       [0.    ],\n",
       "       [0.5   ],\n",
       "       [0.5   ],\n",
       "       [0.5   ],\n",
       "       [0.5   ],\n",
       "       [0.5   ],\n",
       "       [0.    ],\n",
       "       [0.5   ],\n",
       "       [0.    ],\n",
       "       [1.    ],\n",
       "       [1.    ]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.transpose(2,0,1).reshape(-1,y_test.shape[1])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5],\n",
       "       [0. ],\n",
       "       [0. ],\n",
       "       [0.9],\n",
       "       [0.4],\n",
       "       [0. ],\n",
       "       [0.5],\n",
       "       [0. ],\n",
       "       [1. ],\n",
       "       [0.5],\n",
       "       [0. ],\n",
       "       [1. ],\n",
       "       [0.9],\n",
       "       [0.6],\n",
       "       [0. ],\n",
       "       [0.7],\n",
       "       [0.4],\n",
       "       [1. ],\n",
       "       [0. ],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.6],\n",
       "       [0.6],\n",
       "       [0.5],\n",
       "       [0. ],\n",
       "       [0.5],\n",
       "       [0. ],\n",
       "       [1. ],\n",
       "       [1. ]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = predicted\n",
    "p = np.around(p,1)\n",
    "p = np.absolute(p)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## precisión 72%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.41379310344827\n"
     ]
    }
   ],
   "source": [
    "total = len(p)\n",
    "acert = 0\n",
    "for a,b in zip(y_test,p):\n",
    "    if a == b:\n",
    "        acert += 1\n",
    "\n",
    "print(acert/total*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
